{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a utilizar el dataset de Alex Krizhevsky (2009) de imágnes de airplane, automobile, bird, cat, deer, dog, frog, horse, ship y truck, que consiste en 60000 imágenes RGB de 32x32 pixeles equilibradamente distribuidas en las dos clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a reacomodar los tensores para que sean en los 3 rangos de la imagen original. Dejaremos 10000 para validación, 10000 para test y el restante (40000) para entrenamiento. \n",
    "\n",
    "Modificamos las escalas de colores (0 a 255) con valores en una escala que vaya de 0 a 1 y que sean entonces de tipo flotantes.\n",
    "\n",
    "Finalmente, convertimos los labels de arrays one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-fc910092cf97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mlabels_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mlabels_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[0mlabels_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "dire = 'cifar-10-batches-py/'\n",
    "\n",
    "batch_1_dict = unpickle(dire+'data_batch_1')\n",
    "data1 = batch_1_dict[b'data'].reshape(10000, 3, 32, 32)\n",
    "data1 = np.transpose(data1, (0, 2, 3, 1))\n",
    "labels1 = batch_1_dict[b'labels']\n",
    "labels1 = np.asarray(labels1)\n",
    "\n",
    "batch_2_dict = unpickle(dire+'data_batch_2')\n",
    "data2 = batch_2_dict[b'data'].reshape(10000, 3, 32, 32)\n",
    "data2 = np.transpose(data2, (0, 2, 3, 1))\n",
    "labels2 = batch_2_dict[b'labels']\n",
    "labels2 = np.asarray(labels2)\n",
    "\n",
    "batch_3_dict = unpickle(dire+'data_batch_3')\n",
    "data3 = batch_3_dict[b'data'].reshape(10000, 3, 32, 32)\n",
    "data3 = np.transpose(data3, (0, 2, 3, 1))\n",
    "labels3 = batch_3_dict[b'labels']\n",
    "labels3 = np.asarray(labels3)\n",
    "\n",
    "batch_4_dict = unpickle(dire+'data_batch_4')\n",
    "data4 = batch_4_dict[b'data'].reshape(10000, 3, 32, 32)\n",
    "data4 = np.transpose(data4, (0, 2, 3, 1))\n",
    "labels4 = batch_4_dict[b'labels']\n",
    "labels4 = np.asarray(labels4)\n",
    "\n",
    "batch_5_dict = unpickle(dire+'data_batch_5')\n",
    "data_validation = batch_5_dict[b'data'].reshape(10000, 3, 32, 32)\n",
    "data_validation = np.transpose(data_validation, (0, 2, 3, 1))\n",
    "labels_validation = batch_5_dict[b'labels']\n",
    "labels_validation = np.asarray(labels_validation)\n",
    "\n",
    "batch_test = unpickle(dire+'test_batch')\n",
    "data_test = batch_test[b'data'].reshape(10000, 3, 32, 32)\n",
    "data_test = np.transpose(data_test, (0, 2, 3, 1))\n",
    "labels_test = batch_test[b'labels']\n",
    "labels_test = np.asarray(labels_test)\n",
    "\n",
    "data_train = np.concatenate((data1,data2,data3,data4)).astype('float32') / 255 \n",
    "data_validation = data_validation.astype('float32') / 255 \n",
    "data_test = data_test.astype('float32') / 255 \n",
    "labels_train = np.concatenate((labels1,labels2,labels3,labels4))\n",
    "labels_train = to_categorical(labels_train)\n",
    "labels_validation = to_categorical(labels_validation)\n",
    "labels_test = to_categorical(labels_test)\n",
    "print(labels_train.shape, labels_validation, labels_test)\n",
    "print(data_train.shape, data_validation.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir un modelo:\n",
    "* que recibe un tensor con las instancias de imágen con tres ejes con la dimensionalidad (32, 32, 3), \n",
    "* con 3 capas convolucionales 2D, todas con filtros 3x3 y función de activación RELU; la primera con 32 filtros, la segunda con 64 filtros, y la tercera con 128 filtros.\n",
    "* con 3 capas intermedias de MAX pooling que toman las salidas de las capas convolucionales.\n",
    "* con una capa Flatten que permite cambiar la representación de las salidas de las capas convolucionales a un tensor de un solo eje\n",
    "* con dos capas Dense, fully connected, la primera con 512 neuronas y RELU, la segunda, la capa de salida, con 10 neuronas que utilizan una función softmax para clasificar las instancias en diez clases.\n",
    "* una capa de dropout entre las capas densas con probabilidad de 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 356,417\n",
      "Trainable params: 356,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo final tiene en total 356.417 parámetros. Lo compilamos utilizando un optimizador **rmsprop** y una función de activación **categorical_cross_entropy**, y lo entrenamos con 5 épocas con el set de entrenamiento ya procesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 68s 1ms/step - loss: 0.2418 - acc: 0.9256 - val_loss: 0.0603 - val_acc: 0.9813\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.0684 - acc: 0.9800 - val_loss: 0.0518 - val_acc: 0.9868\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 69s 1ms/step - loss: 0.0477 - acc: 0.9860 - val_loss: 0.0370 - val_acc: 0.9908\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 69s 1ms/step - loss: 0.0378 - acc: 0.9889 - val_loss: 0.0428 - val_acc: 0.9893\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.0313 - acc: 0.9910 - val_loss: 0.0356 - val_acc: 0.9907\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=data_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
